import streamlit as st
import pandas as pd
import numpy as np
import joblib
from feature_extractor import URLFeatureExtractor
import matplotlib.pyplot as plt
import plotly.graph_objects as go
from urllib.parse import urlparse
import tldextract

# Load the trained model
@st.cache_resource
def load_model():
    try:
        model = joblib.load('phishing_url_detector.pkl')
        return model
    except FileNotFoundError:
        st.error("Model file 'phishing_url_detector.pkl' not found. Please train the model first.")
        return None

def predict_url_risk(url, model):
    """
    Predict if URL is phishing and calculate risk score
    """
    extractor = URLFeatureExtractor()
    features = extractor.extract_features(url)

    # Select features used in training
    feature_names = [
        'url_length', 'num_dots', 'num_hyphens', 'num_underscores', 'num_slashes',
        'num_question_marks', 'num_equals', 'num_ampersands', 'num_digits', 'num_alphabets',
        'domain_length', 'subdomain_length', 'num_subdomains', 'has_https', 'has_ip',
        'has_at_symbol', 'has_double_slash', 'suspicious_keywords_count', 'special_chars_ratio',
        'path_length', 'num_path_segments', 'query_length', 'num_query_params'
    ]

    # Create feature vector
    feature_vector = np.array([[features[name] for name in feature_names]])

    # Get prediction and probability
    prediction = model.predict(feature_vector)[0]
    probability = model.predict_proba(feature_vector)[0]

    # Risk score (0-100)
    risk_score = probability[1] * 100  # Probability of being phishing

    return prediction, risk_score, features

def get_explanation(features, risk_score):
    """
    Generate human-readable explanation for the prediction
    """
    reasons = []

    if features['url_length'] > 75:
        reasons.append(f"URL is unusually long ({features['url_length']} characters)")
    if features['num_subdomains'] > 2:
        reasons.append(f"Has many subdomains ({features['num_subdomains']})")
    if features['has_ip']:
        reasons.append("Uses IP address instead of domain name")
    if features['suspicious_keywords_count'] > 0:
        reasons.append(f"Contains {features['suspicious_keywords_count']} suspicious keyword(s)")
    if not features['has_https']:
        reasons.append("Does not use HTTPS")
    if features['special_chars_ratio'] > 0.1:
        reasons.append("High ratio of special characters")

    if risk_score > 70:
        risk_level = "High Risk"
        color = "red"
    elif risk_score > 40:
        risk_level = "Medium Risk"
        color = "orange"
    else:
        risk_level = "Low Risk"
        color = "green"

    return reasons, risk_level, color

def create_risk_gauge(risk_score):
    """
    Create a gauge chart for risk score
    """
    fig = go.Figure(go.Indicator(
        mode="gauge+number",
        value=risk_score,
        domain={'x': [0, 1], 'y': [0, 1]},
        title={'text': "Risk Score"},
        gauge={
            'axis': {'range': [0, 100]},
            'bar': {'color': "darkblue"},
            'steps': [
                {'range': [0, 40], 'color': "lightgreen"},
                {'range': [40, 70], 'color': "yellow"},
                {'range': [70, 100], 'color': "red"}
            ],
            'threshold': {
                'line': {'color': "red", 'width': 4},
                'thickness': 0.75,
                'value': 70
            }
        }
    ))

    fig.update_layout(height=300)
    return fig

def main():
    st.set_page_config(
        page_title="AI Phishing URL Detector",
        page_icon="üõ°Ô∏è",
        layout="wide"
    )

    st.title("üõ°Ô∏è AI-Based Phishing & Malicious URL Detection System")
    st.markdown("---")

    # Load model
    model = load_model()
    if model is None:
        return

    # Sidebar
    st.sidebar.header("About")
    st.sidebar.info("""
    This AI-powered system detects phishing and malicious URLs using machine learning.

    **Features:**
    - Real-time URL analysis
    - Risk scoring (0-100)
    - Explainable predictions
    - Feature importance visualization
    """)

    st.sidebar.header("How it works")
    st.sidebar.markdown("""
    1. Enter a URL to analyze
    2. The system extracts 23+ features
    3. ML model predicts phishing probability
    4. Get risk score and explanations
    """)

    # Main content
    col1, col2 = st.columns([2, 1])

    with col1:
        st.subheader("üîç URL Analysis")

        # URL input
        url_input = st.text_input(
            "Enter URL to analyze:",
            placeholder="https://example.com",
            help="Enter the complete URL including http:// or https://"
        )

        if st.button("Analyze URL", type="primary"):
            if url_input:
                with st.spinner("Analyzing URL..."):
                    try:
                        # Make prediction
                        prediction, risk_score, features = predict_url_risk(url_input, model)

                        # Get explanation
                        reasons, risk_level, color = get_explanation(features, risk_score)

                        # Display results
                        st.success("Analysis Complete!")

                        # Risk score gauge
                        st.plotly_chart(create_risk_gauge(risk_score), use_container_width=True)

                        # Prediction result
                        if prediction == 1:
                            st.error(f"‚ö†Ô∏è **{risk_level}**: This URL is classified as PHISHING")
                        else:
                            st.success(f"‚úÖ **{risk_level}**: This URL appears LEGITIMATE")

                        st.metric("Risk Score", f"{risk_score:.1f}/100")

                        # Explanation
                        st.subheader("üìã Analysis Details")
                        if reasons:
                            st.write("**Key indicators that influenced this prediction:**")
                            for reason in reasons:
                                st.write(f"‚Ä¢ {reason}")
                        else:
                            st.write("No significant risk indicators detected.")

                        # URL breakdown
                        st.subheader("üîó URL Breakdown")
                        parsed = urlparse(url_input)
                        domain_info = tldextract.extract(url_input)

                        breakdown_col1, breakdown_col2 = st.columns(2)
                        with breakdown_col1:
                            st.write(f"**Domain:** {domain_info.domain}.{domain_info.suffix}")
                            st.write(f"**Subdomain:** {domain_info.subdomain}")
                            st.write(f"**Protocol:** {parsed.scheme.upper()}")

                        with breakdown_col2:
                            st.write(f"**Path:** {parsed.path}")
                            st.write(f"**Query Params:** {len(parsed.query.split('&')) if parsed.query else 0}")
                            st.write(f"**URL Length:** {len(url_input)} characters")

                    except Exception as e:
                        st.error(f"Error analyzing URL: {str(e)}")
            else:
                st.warning("Please enter a URL to analyze.")

    with col2:
        st.subheader("üìä Model Information")

        # Model stats (placeholder - in real app, load from training)
        st.metric("Model Type", "Random Forest")
        st.metric("Training Accuracy", "95.2%")
        st.metric("Features Used", "23")

        st.subheader("üéØ Top Risk Factors")
        risk_factors = [
            "URL Length",
            "Suspicious Keywords",
            "HTTPS Usage",
            "Special Characters",
            "Subdomain Count"
        ]

        for factor in risk_factors:
            st.write(f"‚Ä¢ {factor}")

        # Disclaimer
        st.warning("""
        **Disclaimer:** This tool provides automated analysis but is not 100% accurate.
        Always exercise caution and verify URLs through additional means.
        """)

if __name__ == "__main__":
    main()
